{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prova Intermediária - Machine Learning\n",
    "\n",
    "**Nome do aluno**: <font color='red'>Escreva seu nome aqui</font>\n",
    "\n",
    "Você deve submeter o trabalho via Blackboard. É de sua responsabilidade garantir que o arquivo correto foi enviado.\n",
    "\n",
    "Se você precisou adicionar arquivos extras à essa prova, assegure-se de que você os está enviando também.\n",
    "\n",
    "A prova é individual e com consulta. Faça o seu trabalho de maneira ética! Se você recebeu ajuda de sistemas de apoio inteligentes (por exemplo, ChatGPT, Bard, CoPilot, etc) DECLARE CLARAMENTE ONDE VOCÊ RECEBEU AJUDA para não configurar plágio (definido como \"declarar como próprio o trabalho construido por outrem - neste caso um sistema computacional\")\n",
    "\n",
    "São 10 questões, cada uma valendo 1 ponto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contexto do problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos trabalhar com um *dataset* de processadores antigos, da década de 1980! Nesses tempos o *hardware* era muito mais simples que nos dias atuais. O *dataset* possui atributos referentes ao *hardware* de diferentes máquinas, e o *target* é uma métrica de desempenho computacional relativo (relativo a qual valor-base? Honestamente, não sei, mas paciência).\n",
    "\n",
    "Aqui está a documentação original do *dataset*:\n",
    "\n",
    "\n",
    "```\n",
    "1. Title: Relative CPU Performance Data \n",
    "\n",
    "2. Source Information\n",
    "   -- Creators: Phillip Ein-Dor and Jacob Feldmesser\n",
    "     -- Ein-Dor: Faculty of Management; Tel Aviv University; Ramat-Aviv; \n",
    "        Tel Aviv, 69978; Israel\n",
    "   -- Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779   \n",
    "   -- Date: October, 1987\n",
    " \n",
    "3. Past Usage:\n",
    "    1. Ein-Dor and Feldmesser (CACM 4/87, pp 308-317)\n",
    "       -- Results: \n",
    "          -- linear regression prediction of relative cpu performance\n",
    "          -- Recorded 34% average deviation from actual values \n",
    "    2. Kibler,D. & Aha,D. (1988).  Instance-Based Prediction of\n",
    "       Real-Valued Attributes.  In Proceedings of the CSCSI (Canadian\n",
    "       AI) Conference.\n",
    "       -- Results:\n",
    "          -- instance-based prediction of relative cpu performance\n",
    "          -- similar results; no transformations required\n",
    "    - Predicted attribute: cpu relative performance (numeric)\n",
    "\n",
    "4. Relevant Information:\n",
    "   -- The estimated relative performance values were estimated by the authors\n",
    "      using a linear regression method.  See their article (pp 308-313) for\n",
    "      more details on how the relative performance values were set.\n",
    "\n",
    "5. Number of Instances: 209 \n",
    "\n",
    "6. Number of Attributes: 10 (6 predictive attributes, 2 non-predictive, \n",
    "                             1 goal field, and the linear regression's guess)\n",
    "\n",
    "7. Attribute Information:\n",
    "   1. vendor name: 30 \n",
    "      (adviser, amdahl,apollo, basf, bti, burroughs, c.r.d, cambex, cdc, dec, \n",
    "       dg, formation, four-phase, gould, honeywell, hp, ibm, ipl, magnuson, \n",
    "       microdata, nas, ncr, nixdorf, perkin-elmer, prime, siemens, sperry, \n",
    "       sratus, wang)\n",
    "   2. Model Name: many unique symbols\n",
    "   3. MYCT: machine cycle time in nanoseconds (integer)\n",
    "   4. MMIN: minimum main memory in kilobytes (integer)\n",
    "   5. MMAX: maximum main memory in kilobytes (integer)\n",
    "   6. CACH: cache memory in kilobytes (integer)\n",
    "   7. CHMIN: minimum channels in units (integer)\n",
    "   8. CHMAX: maximum channels in units (integer)\n",
    "   9. PRP: published relative performance (integer)\n",
    "  10. ERP: estimated relative performance from the original article (integer)\n",
    "\n",
    "8. Missing Attribute Values: None\n",
    "\n",
    "9. Class Distribution: the class value (PRP) is continuously valued.\n",
    "   PRP Value Range:   Number of Instances in Range:\n",
    "   0-20               31\n",
    "   21-100             121\n",
    "   101-200            27\n",
    "   201-300            13\n",
    "   301-400            7\n",
    "   401-500            4\n",
    "   501-600            2\n",
    "   above 600          4\n",
    "\n",
    "Summary Statistics:\n",
    "\t   Min  Max   Mean    SD      PRP Correlation\n",
    "   MCYT:   17   1500  203.8   260.3   -0.3071\n",
    "   MMIN:   64   32000 2868.0  3878.7   0.7949\n",
    "   MMAX:   64   64000 11796.1 11726.6  0.8630\n",
    "   CACH:   0    256   25.2    40.6     0.6626\n",
    "   CHMIN:  0    52    4.7     6.8      0.6089\n",
    "   CHMAX:  0    176   18.2    26.0     0.6052\n",
    "   PRP:    6    1150  105.6   160.8    1.0000\n",
    "   ERP:   15    1238  99.3    154.8    0.9665\n",
    "\n",
    "```\n",
    "\n",
    "Para melhor entender este *dataset*, segue uma explicação de cada atributo:\n",
    "\n",
    "- `vendor name`: Nome do fabricante do processador.\n",
    "- `Model Name`: Nome do modelo do processador.\n",
    "- `MYCT`: Duração do ciclo de *clock* deste processador, em nanossegundos. Nesta época as frequências de trabalho das CPUs eram medidas em kHz ou MHz, e portando as durações de ciclo eram da ordem de magnitude de centenas de nanossegundos.\n",
    "- `MMIN`, `MMAX`: Faixa de variação permitida para a quantidade de memória RAM aceita por esse processador.\n",
    "- `CACH`: Tamanho da memória *cache* deste processador. Note que alguns processadores nem tinham memória *cache*.\n",
    "- `CHMIN`, `CHMAX`: Faixa de valores de quantidade de canais de comunicação deste processador com periféricos.\n",
    "- `PRP`: Performance relativa. <font color=\"red\">Este é o *target*</font>\n",
    "- `ERP`: Performance estimada pelos autores do artigo citado acima - <font color=\"red\">Não deve ser usado como *feature*!</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    'Vendor',\n",
    "    'Model',\n",
    "    'MYCT',\n",
    "    'MMIN',\n",
    "    'MMAX',\n",
    "    'CACH',\n",
    "    'CHMIN',\n",
    "    'CHMAX',\n",
    "    'PRP',\n",
    "    'ERP',\n",
    "]\n",
    "\n",
    "df = pd.read_csv('machine.data', names=column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = shuffle(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação inicial do *dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Vendor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vendor_counts = df['Vendor'].value_counts()\n",
    "vendor_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = vendor_counts \\\n",
    "    .sort_values(ascending=True) \\\n",
    "    .plot \\\n",
    "    .barh(figsize=(10, 10))\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tem muitos fabricantes com poucos modelos de CPU. Vamos agrupá-los em uma categoria `others`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "small_vendors = list(vendor_counts[vendor_counts <= 10].index)\n",
    "small_vendors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df['Vendor'].isin(small_vendors), 'Vendor'] = 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vendor_counts = df['Vendor'].value_counts()\n",
    "vendor_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = vendor_counts \\\n",
    "    .sort_values(ascending=True) \\\n",
    "    .plot \\\n",
    "    .barh(figsize=(10, 5))\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Vendor'] = df['Vendor'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nome do modelo não significa nada, vamos descartar essa coluna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estatísticas descritivas simples e visualizações\n",
    "\n",
    "As estatísticas descritivas simples (contagens, médias, medianas, desvios, etc.) são a primeira verificação do dataset, para que tenhamos uma noção da natureza dos dados. Tendo esse entendimento inicial, teremos melhor capacidade de conceber boas visualizações dos dados para continuar a ampliar nosso entendimento da situação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "def visualize(df):\n",
    "    print('Estatísticas descritivas das variáveis contínuas')\n",
    "    print(df.describe(include=np.number))\n",
    "    print()\n",
    "\n",
    "    print('Estatísticas descritivas das variáveis categóricas')\n",
    "    print(df.describe(include='category'))\n",
    "    print()\n",
    "\n",
    "    df_train_numericals = df.select_dtypes(np.number)\n",
    "\n",
    "    print('Correlações entre as variáveis numéricas')\n",
    "    print(df_train_numericals.corr())\n",
    "    print()\n",
    "\n",
    "    print('Visualizações')\n",
    "\n",
    "    pd.plotting.scatter_matrix(df_train_numericals, figsize=(12, 12))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    with warnings.catch_warnings(action='ignore', category=FutureWarning):\n",
    "        df.plot.box(\n",
    "            by='Vendor',\n",
    "            layout=(4, 2),\n",
    "            figsize=(8, 16),\n",
    "            xlabel='Model',\n",
    "            rot=90,\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot-encoding, e separando *features* e *target*\n",
    "\n",
    "Lembre-se que a coluna `ERP` não é nem *feature*, nem *target*: trata-se dos valores preditos de desempenho conforme descrito no artigo dos autores do *dataset*. Não vamos usar essa coluna no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['PRP', 'ERP', 'Vendor_others']).copy()\n",
    "y = df['PRP'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prova intermediária"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte prática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao longo das questões seguintes você vai construir um projeto de regressão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 1**: Analise o desempenho RMSE de um modelo de regressão linear para estes dados usando validação cruzada com 5 partições.\n",
    "\n",
    "Dica: use a métrica `\"neg_mean_squared_error\"` no argumento `scoring` da função `cross_val_score`, e corrija adequadamente os escores obtidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 2**: Construa uma função que recebe a tabela de *features* (i.e. `X_train` ou `X_test`) e retorna os dados com *feature engineering* conforme descrito a seguir:\n",
    "\n",
    "- Primeiro transforme a coluna `MYCT`: aplique uma transformação do tipo $f(x) = 1 / x$.\n",
    "- Normalize (`StandardScaler` no scikit-learn) **apenas as colunas** `MYCT` (transformada), `MMIN`, `MMAX`, `CACH`, `CHMIN`, `CHMAX`.\n",
    "- Depois, construa *features* polinomiais (`PolynomialFeatures` no scikit-learn) de grau 2 **apenas para as colunas** `MYCT` (transformada), `MMIN`, `MMAX`, `CACH`, `CHMIN`, `CHMAX`.\n",
    "\n",
    "Não é obrigatório o uso de `Pipeline` ou `ColumnTransformer` - esteja livre para usá-los ou não, conforme preferir.\n",
    "\n",
    "Aplique esta função para processar os dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 3**: Analise o desempenho RMSE de um modelo de regressão linear para estes novos dados usando validação cruzada com 5 partições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 4**: Compare os dois modelos investigados nas questões anteriores. Existe evidência de que o modelo mais complexo é melhor que o modelo simples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 5**: Retreine o modelo escolhido (se não houver evidencia de superioridade de um modelo sobre o outro, escolha o que você quiser) no conjunto de treinamento completo e meça o desempenho final no conjunto de teste. (O modelo continua sendo uma regressão linear, o que muda é o uso do conjunto de treinamento original ou o com *feature engineering*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 6**: Compare o desempenho do seu modelo preditivo com o desempenho do modelo preditivo dos autores do *dataset*, de acordo com as predições vistas na coluna `ERP`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 7**: Quais são os *outliers* do seu modelo preditivo? Ou seja: para quais CPUs no conjunto de teste temos o maior erro, em valores absolutos, na direção positiva e na direção negativa do erro?\n",
    "\n",
    "Dica: ao descobrir o índice dos outliers, retorne ao conjunto de dados original e descubra a marca e modelo da CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte conceitual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 8**: Perguntei ao \"ChatGPT\" o seguinte: \"No contexto de machine learning, explique com suas palavras e em menos de 100 palavras os conceitos de sensibilidade e especificidade.\". A resposta foi:\n",
    "\n",
    "\"Sensibilidade (ou recall) e especificidade são métricas de desempenho em modelos de machine learning para classificação binária.\n",
    "\n",
    "Sensibilidade mede a capacidade do modelo em identificar corretamente todos os casos positivos, ou seja, a proporção de verdadeiros positivos (amostras positivas classificadas corretamente) em relação ao total de casos positivos.\n",
    "\n",
    "Especificidade, por outro lado, avalia a capacidade do modelo em identificar corretamente todos os casos negativos, ou seja, a proporção de verdadeiros negativos (amostras negativas classificadas corretamente) em relação ao total de casos negativos.\n",
    "\n",
    "Ambas as métricas são importantes para avaliar o desempenho do modelo em diferentes contextos, dependendo das necessidades do problema em questão.\"\n",
    "\n",
    "Construa um exemplo do seu cotidiano como aluno do Insper em que o trade-off sensibilidade versus especificidade poderia ser demonstrado. Você não deve incluir exemplos de projetos ou aplicativos de machine learning, ou provas academicas em geral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 9**: Perguntei ao \"ChatGPT\" o seguinte: \"Explique a curva ROC para um padeiro\". A resposta foi:\n",
    "\n",
    "\"Claro! Vamos adaptar a explicação da curva ROC (Receiver Operating Characteristic) para o contexto de um padeiro.\n",
    "\n",
    "Imagine que um padeiro está tentando determinar a qualidade de duas marcas de farinha (Marca A e Marca B) para fazer seu pão. Ele quer escolher a farinha que produz o pão mais saboroso.\n",
    "\n",
    "A curva ROC pode ser comparada à capacidade do padeiro de distinguir entre as duas marcas de farinha. Neste caso:\n",
    "\n",
    "- Ele testa ambas as farinhas e avalia a qualidade de seus pães.\n",
    "- Ele varia a quantidade de farinha de cada marca nas receitas para observar como isso afeta a qualidade do pão.\n",
    "- Em seguida, ele cria uma curva ROC, onde o eixo X representa a quantidade de farinha da Marca A usada na receita e o eixo Y representa a quantidade da Marca B.\n",
    "- Cada ponto na curva ROC representa uma combinação diferente de quantidades de farinha, e a curva mostra quão bem ele pode distinguir a qualidade dos pães feitos com as duas marcas.\n",
    "- A área sob a curva ROC (AUC) indica o quão eficaz o padeiro é em diferenciar as farinhas; quanto maior a AUC, melhor a capacidade de escolha.\n",
    "\n",
    "Assim, a curva ROC ajuda o padeiro a tomar uma decisão informada sobre qual farinha usar para fazer pães deliciosos com base na quantidade de cada marca em sua receita.\"\n",
    "\n",
    "Ou seja, a resposta não faz o menor sentido.\n",
    "\n",
    "Construa uma explicação melhor de curva ROC para um padeiro, que não sabe nada de *machine learning* mas sabe conduzir os negócios de uma padaria com muito sucesso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 10**: Construa um exemplo concreto de como o machine learning pode ajudar a aumentar a eficiência do trânsito de São Paulo. O exemplo deve ser específico de *machine learning*, e não de inteligência artificial no sentido mais amplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
