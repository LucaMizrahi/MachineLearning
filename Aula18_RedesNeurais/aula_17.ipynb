{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução às redes neurais e TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para chegar à implementação de uma rede neural simples, vamos começar com um problema velho conhecido nosso: a regressão logística.\n",
    "\n",
    "Relembrando: a regressão logística (que não é uma regressão, e sim um modelo de classificação) usa a função logística:\n",
    "\n",
    "$$\n",
    "y = \\sigma(x) = \\frac{1}{1 + \\exp(-x)}\n",
    "$$\n",
    "\n",
    "Vamos implementá-la e visualizá-la:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f175be760a65403f99c45b2bddb3a8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def logistic(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "\n",
    "xs = np.linspace(-10.0, 10.0, 200)\n",
    "ys = logistic(xs)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xs, ys)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Função logística:\\n$y = 1/(1 + \\exp(-x))$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No contexto da regressão logística, a função logística será usada para representar a probabilidade de que um objeto $x$ pertença à classe positiva.\n",
    "\n",
    "Do jeito que está, a função logística permite apenas distinguir valores negativos de $x$ (quando $\\sigma(x) < 0.5$ de valores positivos de $x$ (quando $\\sigma(x) > 0.5$). Para \"esticar\" a função logística podemos usar um peso aplicado a $x$: quando esse peso é maior que $1$ a função encolhe, e quando é menor que $1$ a função alarga:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d4207a7f1b4ca98453e15d113874fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = 3\n",
    "ys = logistic(w * xs)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xs, ys)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(f\"Função logística encurtada:\\n$y = 1/(1 + \\exp(-{w} x))$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debcd318cb4f48a0b23084039f0ccb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = 0.5\n",
    "ys = logistic(w * xs)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xs, ys)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(f\"Função logística alargada:\\n$y = 1/(1 + \\exp(-{w} x))$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mover a função logística, podemos somar uma constante ao argumento $x$. Valores positivos da constante deslocam a função logística para a direção negativa, e valores negativos deslocam a função para a direção positiva:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d078b8ce34914394aff55edaa215be8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = 3\n",
    "ys = logistic(xs + b)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xs, ys)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(f\"Função logística deslocada para a esquerda:\\n$y = 1/(1 + \\exp(-x + {b}))$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d3530fca314ac393ba8b53573b5f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = -3\n",
    "\n",
    "ys = logistic(xs + b)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xs, ys)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(f\"Função logística deslocada para a direita:\\n$y = 1/(1 + \\exp(-x - {-b}))$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinando os dois elementos (o peso e a constante) podemos mover e esticar a função logística à vontade.\n",
    "\n",
    "E se a entrada $x$ for multivalorada? Para considerar um exemplo totalmente ao acaso, queremos distinguir entre dois tipos de flores a partir do comprimento e da largura da pétala. Neste caso nossa entrada $x$ tem dois valores. Por conveniência, vamos representar uma entrada como uma matriz linha, para ficar consistente com a nossa representação futura de multiplos pontos como uma matriz:\n",
    "\n",
    "$$\n",
    "x = \\left[\n",
    "\\begin{matrix}\n",
    "x_0 & x_1\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "Nossos pesos agora são um vetor de dois valores:\n",
    "\n",
    "$$\n",
    "w = \\left[\n",
    "\\begin{matrix}\n",
    "w_0 \\\\\n",
    "w_1\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "e nossa constante continua sendo um valor apenas.\n",
    "\n",
    "A combinação de valores pré-função-logística fica sendo:\n",
    "\n",
    "$$\n",
    "v = x w + b\n",
    "$$\n",
    "\n",
    "onde o produto da expressão é uma multiplicação de matrizes.\n",
    "\n",
    "Vamos implementar esta operação em separado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(w, b, x):\n",
    "    return x @ w + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A operação `@` para multiplicação de matrizes foi introduzida no Python 3.5, na PEP 465.\n",
    "\n",
    "Vamos visualizar o resultado de aplicar um vetor de pesos e uma constante à nossa função logística. Primeiro vamos gerar vários pontos cobrindo o quadrado de lado $20.0$ centrado na origem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.linspace(-10.0, 10.0, 200)\n",
    "ys = np.linspace(-10.0, 10.0, 200)\n",
    "\n",
    "Xs, Ys = np.meshgrid(xs, ys)\n",
    "Xs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos rearranjar estes valores na forma de uma matriz de amostras de $200 \\times 200 = 40000$ linhas e $2$ colunas (uma para os `Xs` e outra para os `Ys`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.c_[Xs.reshape(-1, 1), Ys.reshape(-1, 1)]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos aplicar diretamente as funções `linear(w, b, x)` e `logistic(x)`! Pela magia do `numpy`, as operações já estão definidas para operação matricial. Só precisamos definir corretamente os pesos e a constante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array(\n",
    "    [\n",
    "        [-3.0],\n",
    "        [5.0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "b = -2.0\n",
    "\n",
    "v = linear(w, b, X)\n",
    "z = logistic(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos retornar a forma do array `z` para que seja compatível com `Xs` e `Ys`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zs = z.reshape(Xs.shape)\n",
    "Zs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora é só plotar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb7e94529e14d8da4779ab7ac5f9b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection=\"3d\")\n",
    "ax.plot_surface(Xs, Ys, Zs, cmap=cm.coolwarm)\n",
    "plt.xlabel(\"$x_0$\")\n",
    "plt.ylabel(\"$x_1$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar a estrutura que criamos aqui com o diagrama a seguir:\n",
    "\n",
    "![](logistic.png)\n",
    "\n",
    "Neste diagrama, os pesos incluidos nas arestas representam multiplicação, e o circulo representa a soma dos valores entrantes.\n",
    "\n",
    "Isto é o nosso primeiro neurônio artificial! No linguajar das redes neurais, temos aqui uma camada de $2$ entradas, $1$ saída, e *função de ativação* logística.\n",
    "\n",
    "A questão agora é: como treinar a rede?\n",
    "\n",
    "**Atividade**: Selecione manualmente pesos e constante que façam com que a regressão logística resolva o seguinte problema de classificação:\n",
    "\n",
    "| $x_0$ | $x_1$ | $y$ |\n",
    "|-------|-------|-----|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 0 |\n",
    "| 1 | 0 | 0 |\n",
    "| 1 | 1 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R**: $w_0 = 1$, $w_1 = 1$, $b = -1.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.]]),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]]),\n",
       " array([[3.05902227e-07],\n",
       "        [6.69285092e-03],\n",
       "        [6.69285092e-03],\n",
       "        [9.93307149e-01]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array(\n",
    "    [\n",
    "        [10.0],\n",
    "        [10.0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "b = -15.0\n",
    "\n",
    "X = np.array(\n",
    "    [\n",
    "        [0.0, 0.0],\n",
    "        [0.0, 1.0],\n",
    "        [1.0, 0.0],\n",
    "        [1.0, 1.0],\n",
    "    ]\n",
    ")\n",
    "y = np.array(\n",
    "    [\n",
    "        [0.0],\n",
    "        [0.0],\n",
    "        [0.0],\n",
    "        [1.0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "v = linear(w, b, X)\n",
    "z = logistic(v)\n",
    "\n",
    "X, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementando a regressão logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função logística acima é um *modelo paramétrico*. Com os parâmetros corretos, permite atribuir a uma amostra $x$ uma probabilidade $\\hat{y}$ (note o uso de chapeu para indicar *valor estimado*) de pertencimento à classe positiva.\n",
    "\n",
    "Como podemos *definir* o que são parâmetros corretos? Como de costume em *machine learning* podemos definir os parâmetros corretos como sendo aqueles que minimizam um valor médio de *perda*, *custo* ou *erro* para um conjunto de amostras de treinamento.\n",
    "\n",
    "No caso da regressão logística, a *perda* para uma amostra $(x, y)$ é dada pela *entropia cruzada*:\n",
    "\n",
    "$$\n",
    "l(y, \\hat{y}) = -y \\log(\\hat{y}) - (1 - y) \\log(1 - \\hat{y})\n",
    "$$\n",
    "\n",
    "A perda média sobre um conjunto de $m$ amostras de dimensão (features) $n$, representado como uma matriz $X_{m \\times n}$ e um vetor $y_{m \\times 1}$, é dada por:\n",
    "\n",
    "$$\n",
    "L(y, \\hat{y}) = \\frac{1}{m} \\sum_{i = 1}^{m} l(y_i, \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "Pela magia do `numpy`, a implementação abaixo funciona para qualquer número de amostras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_pred):\n",
    "    m = y.shape[0]\n",
    "    cross_entropy = (1.0 / m) * np.sum(\n",
    "        -y * np.log(y_pred) - (1 - y) * np.log(1 - y_pred)\n",
    "    )\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos um modelo e uma definição de perda, que deve ser minimizada. Falta definir o algoritmo de otimização. Como de costume, vamos usar o *gradient descent*. Devemos lembrar que, ao fixar as amostras de treinamento, nossa função de perda passa a depender somente dos pesos e da constante:\n",
    "\n",
    "$$\n",
    "L(y, \\hat{y}(w, b, X)) = L(w, b) \\, \\text{para $X$ e $y$ fixos}\n",
    "$$\n",
    "\n",
    "O algoritmo *gradient descent* vai precisar dos gradientes da função de perda média em relação aos parâmetros $w$ e $b$:\n",
    "\n",
    "$$\n",
    "\\nabla_w L(w, b) = \\frac{\\partial L}{\\partial w} =  \\frac{1}{m} X^T (\\hat{y} - y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla_b L(w, b) = \\frac{dL}{db} =  \\frac{1}{m} \\sum_{i = 1}^{m} (\\hat{y}_i - y_i)\n",
    "$$\n",
    "\n",
    "(acredite)\n",
    "\n",
    "Abaixo temos a implementação desta função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(X, y, y_pred):\n",
    "    m = y.shape[0]\n",
    "    grad_w = (1.0 / m) * X.transpose() @ (y_pred - y)\n",
    "    grad_b = (1.0 / m) * np.sum(y_pred - y)\n",
    "    return grad_w, grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar um conjunto de exemplos de treinamento bem simples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(\n",
    "    [\n",
    "        [0.0, 0.0],\n",
    "        [0.0, 1.0],\n",
    "        [1.0, 0.0],\n",
    "        [1.0, 1.0],\n",
    "    ]\n",
    ")\n",
    "y = np.array(\n",
    "    [\n",
    "        [0.0],\n",
    "        [0.0],\n",
    "        [0.0],\n",
    "        [1.0],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos inicializar os *parâmetros treináveis* (os pesos e a constante). Para nosso exemplo simples de regressão logística a inicialização dos parâmetros não é tão crítica, mas para uma rede neural complexa a inicialização é assunto muito delicado, e pesquisas continuam acontecendo nessa área!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array(\n",
    "    [\n",
    "        [0.0],\n",
    "        [0.0],\n",
    "    ]\n",
    ")\n",
    "b = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos implementar o algoritmo de otimização. O correto é monitorar o erro e parar quando o erro não melhorar mais, mas por simplicidade vamos omitir esta parte do algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 1000\n",
    "tol = 1e-6\n",
    "alpha = 1.0\n",
    "\n",
    "perda = []  # Para poder plotar a perda depois.\n",
    "\n",
    "for _ in range(max_epochs):\n",
    "    y_pred = logistic(linear(w, b, X))\n",
    "    eps = loss(y, y_pred)\n",
    "    perda.append(eps)\n",
    "\n",
    "    grad_w, grad_b = grad(X, y, y_pred)\n",
    "    w -= alpha * grad_w\n",
    "    b -= alpha * grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017431844934779856"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[7.41431138],\n",
       "        [7.41431138]]),\n",
       " -11.294073552477853)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97adf4b2029649f1a9461928bda95f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(perda)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"perda\")\n",
    "plt.title(\"Curva de aprendizado\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora testar o modelo para as amostras de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.24463146e-05],\n",
       "       [2.02377122e-02],\n",
       "       [2.02377122e-02],\n",
       "       [9.71654974e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(linear(w, b, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que funcionou bem!\n",
    "\n",
    "Relembrando: para fazer a regressão logística acontecer precisamos dos seguintes ingredientes:\n",
    "\n",
    "- O modelo\n",
    "- A função de perda\n",
    "- O algoritmo de otimização\n",
    "    - Este inclui a definição de como inicializar os parâmetros do modelo!\n",
    "    \n",
    "Sempre que formos trabalhar com redes neurais teremos que especificar todos esses ingredientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma das coisas complicadas do código acima é ter que determinar manualmente (papel e caneta, ou processador simbólico) a derivada da perda média em relação aos parâmetros. É um processo maçante e sujeito a erros de atenção. Ou seja, é o caso perfeito para o uso de computadores!\n",
    "\n",
    "Em uma primeira abordagem podemos imaginar o calculo da derivada da perda média usando um processo numérico simples:\n",
    "\n",
    "$$\n",
    "\\frac{df}{dx} \\approx \\frac{\\Delta f}{\\Delta x}\n",
    "$$\n",
    "\n",
    "Por exemplo, suponha que desejamos calcular o gradiente da função $f(x) = x^2 y + y + 2$ (o exemplo do livro) no ponto $x = 3, y = 4$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "24.003999999997916 9.99999999999801\n"
     ]
    }
   ],
   "source": [
    "def f(x, y):\n",
    "    return x ** 2 * y + y + 2\n",
    "\n",
    "\n",
    "def gradiente_numerico(f, x, y):  # Vale para qualquer função f.\n",
    "    h = 1e-3\n",
    "    fx = (f(x + h, y) - f(x, y)) / h\n",
    "    fy = (f(x, y + h) - f(x, y)) / h\n",
    "    return fx, fy\n",
    "\n",
    "\n",
    "x = 3\n",
    "y = 4\n",
    "\n",
    "print(f(x, y))\n",
    "\n",
    "grad_x, grad_y = gradiente_numerico(f, x, y)\n",
    "print(grad_x, grad_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece bom, mas sofre de problemas de precisão numérica para funções mais complicadas. Podemos também respirar fundo e determinar o gradiente analiticamente (i.e. \"na mão\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 10\n"
     ]
    }
   ],
   "source": [
    "def gradiente_analitico(x, y):  # Só vale para a função f(x,y) acima.\n",
    "    fx = 2 * x * y\n",
    "    fy = x ** 2 + 1\n",
    "    return fx, fy\n",
    "\n",
    "\n",
    "grad_x, grad_y = gradiente_analitico(x, y)\n",
    "\n",
    "print(grad_x, grad_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso a precisão é máxima, mas temos que mudar todo o código toda vez que a função for modificada. Além disso, para funções muito complicadas essa abordagem leva muito tempo.\n",
    "\n",
    "A abordagem mais comum para o cálculo de derivadas em *deep learning* é a auto-diferenciação. Nesta abordagem, a computação é vista como um *grafo* direcionado pelo qual fluem valores. Por exemplo, a função $f(x) = x^2 y + y + 2$ pode ser representada pelo grafo abaixo:\n",
    "\n",
    "![](flow.png)\n",
    "\n",
    "A computação flui da entrada para a saída conforme ilustrado abaixo:\n",
    "\n",
    "![](flow2.png)\n",
    "\n",
    "Joia, mas e como calcular a derivada do resultado em relação às variáveis iniciais $x$ e $y$? Para tanto vamos lembrar da *regra da cadeia*: se $y = h(g(f(x)))$, então\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{dy}{dh} \\cdot \\frac{dh}{dg} \\cdot \\frac{dg}{df} \\cdot \\frac{df}{dx} \n",
    "$$\n",
    "\n",
    "Note que cada função ($f(\\cdot)$, $g(\\cdot)$, etc.) necessita apenas de calculo de sua própria derivada. A derivada completa é obtida através da composição das várias derivadas existentes.\n",
    "\n",
    "Quando o processo de cálculo das derivadas começa da última função ($h(\\cdot)$) e vai sendo acumulado do fim para o começo temos o chamado *reverse-mode autodiff*. Começamos com o valor $1$ no final, pois é a derivada da saída contra ela mesma:\n",
    "\n",
    "![](reverse1.png )\n",
    "\n",
    "Agora propagamos de volta (em inglês: *back-propagate*!) esses gradientes da saída do bloco para a entrada do bloco:\n",
    "\n",
    "![](reverse2.png )\n",
    "\n",
    "Continuamos o processo:\n",
    "\n",
    "![](reverse3.png)\n",
    "\n",
    "Mais um pouco:\n",
    "\n",
    "![](reverse4.png)\n",
    "\n",
    "E para terminar:\n",
    "\n",
    "![](reverse5.png)\n",
    "\n",
    "Ufa! Esse processo parece complicado (e é!) e maçante (idem!), mas é *á prova de bala*: pode ser implementado em um computador! Tudo que temos que fazer é implementar os blocos, e neles implementar dois métodos: `evaluate()` calcula o valor do bloco baseado nas entradas, e `backpropagate()` calcula os gradientes *nas entradas* baseado no gradiente recebido *na saida*!\n",
    "\n",
    "**Atividade**: Construa o grafo computacional da função $f(x, y) = x sin(y) + 4 y$ e simule o calculo do gradiente $\\nabla f(4, 2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E para provar que isso funciona, vamos implementar um grafo computacional simples. Vamos começar pela classe que representa a constante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Const:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def evaluate(self):\n",
    "        return self.value\n",
    "\n",
    "    def backpropagate(self, gradient):\n",
    "        pass  # Ignora a propagação de gradiente para uma simples constante, não faz sentido.\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "dois = Const(2.0)\n",
    "print(dois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora implementar as variáveis. Variáveis e constantes são o ponto de partida do grafo computacional, e portanto são o ponto terminal do processo de *backpropagation* do gradiente. Em uma variável, todo gradiente recebido é acumulado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Var:\n",
    "    def __init__(self, name, init_value=0):\n",
    "        self.value = init_value\n",
    "        self.name = name\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.gradient = (\n",
    "            0.0  # Um bom lugar para resetar o gradiente antes do backpropagate.\n",
    "        )\n",
    "        return self.value\n",
    "\n",
    "    def backpropagate(self, gradient):\n",
    "        self.gradient += gradient  # Acumula os gradientes recebidos.\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.name}:{self.value})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x:3.0) (y:4.0)\n",
      "3.0 4.0\n"
     ]
    }
   ],
   "source": [
    "x = Var(\"x\", 3.0)\n",
    "y = Var(\"y\", 4.0)\n",
    "print(x, y)\n",
    "print(x.evaluate(), y.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As próximas operações recebem valores de entrada e produzem valores de saida. Vamos começar pela soma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add:\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a  # Uma entrada.\n",
    "        self.b = b  # Outra entrada.\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.value = self.a.evaluate() + self.b.evaluate()\n",
    "        return self.value\n",
    "\n",
    "    def backpropagate(self, gradient):\n",
    "        self.a.backpropagate(gradient)\n",
    "        self.b.backpropagate(gradient)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.a} + {self.b}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x:3.0) + 2.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "soma_dois = Add(x, dois)\n",
    "print(soma_dois)\n",
    "print(soma_dois.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a multiplicação temos que tomar um cuidado: se $f(x,y) = x y$, então $\\frac{\\partial f}{\\partial x} = y$ e $\\frac{\\partial f}{\\partial y} = x$.\n",
    "\n",
    "Então na hora de *backpropagate* os gradientes, temos que propaga-los diferentemente para cada entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mul:\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a  # Uma entrada.\n",
    "        self.b = b  # Outra entrada.\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.value = self.a.evaluate() * self.b.evaluate()\n",
    "        return self.value\n",
    "\n",
    "    def backpropagate(self, gradient):\n",
    "        self.a.backpropagate(gradient * self.b.value)\n",
    "        self.b.backpropagate(gradient * self.a.value)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.a}) * ({self.b})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((x:3.0)) * ((x:3.0))\n",
      "9.0\n"
     ]
    }
   ],
   "source": [
    "a = Mul(x, x)\n",
    "print(a)\n",
    "print(a.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso temos todos os elementos para construir nosso grafo computacional para a função $f(x) = x^2 y + y + 2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((x:3.0)) * ((x:3.0))) * ((y:4.0)) + (y:4.0) + 2.0\n",
      "42.0\n"
     ]
    }
   ],
   "source": [
    "x = Var(\"x\", 3.0)\n",
    "y = Var(\"y\", 4.0)\n",
    "\n",
    "a = Mul(x, x)\n",
    "b = Mul(a, y)\n",
    "c = Add(b, y)\n",
    "z = Add(c, Const(2.0))\n",
    "\n",
    "print(z)\n",
    "print(z.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciona! Mas e os gradientes? Primeiro vamos retro-propagar (*backpropagate*?) os gradientes, começando pelo $\\frac{dz}{dz} = 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backpropagate(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E agora vamos consultar os valores dos gradientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcionou perfeitamente!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade**: Implemente um nó que calcula $sin(x)$. Implemente o grafo da função da atividade anterior: $f(x, y) = x sin(y) + 4 y$. Compare seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sin:\n",
    "    def __init__(self, a):\n",
    "        self.a = a\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.value = np.sin(self.a.evaluate())\n",
    "        return self.value\n",
    "\n",
    "    def backpropagate(self, gradient):\n",
    "        self.a.backpropagate(gradient * np.cos(self.a.value))\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"sin({self.a})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sin((y:2.0))) * ((x:4.0)) + (4.0) * ((y:2.0))\n"
     ]
    }
   ],
   "source": [
    "x = Var(\"x\", 4.0)\n",
    "y = Var(\"y\", 2.0)\n",
    "quatro = Const(4.0)\n",
    "\n",
    "a = Sin(y)\n",
    "b = Mul(a, x)\n",
    "c = Mul(quatro, y)\n",
    "z = Add(b, c)\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9092974268256817\n",
      "2.3354126538114306\n"
     ]
    }
   ],
   "source": [
    "z.evaluate()\n",
    "z.backpropagate(1.0)\n",
    "\n",
    "print(x.gradient)\n",
    "print(y.gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementando a regressão logística com autodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mostrar que esse tal de autodiff funciona para aplicações reais, vamos implementar a regressão logística com o autodiff. Para isso precisamos de mais dois blocos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log:\n",
    "    def __init__(self, a):\n",
    "        self.a = a\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.value = np.log(self.a.evaluate())\n",
    "        return self.value\n",
    "\n",
    "    def backpropagate(self, gradient):\n",
    "        self.a.backpropagate(gradient * 1.0 / self.a.value)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"log({self.a})\"\n",
    "\n",
    "\n",
    "class Logistic:\n",
    "    def __init__(self, a):\n",
    "        self.a = a\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.value = 1.0 / (1.0 + np.exp(-self.a.evaluate()))\n",
    "        return self.value\n",
    "\n",
    "    def backpropagate(self, gradient):\n",
    "        self.a.backpropagate(gradient * self.value * (1.0 - self.value))\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"s({self.a})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos implementar a regressão logística. Vamos apenas rodar o passo de otimização por um número fixo de vezes para simplificar o código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "max_iter = 1000\n",
    "\n",
    "Xs = [\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "]\n",
    "ys = [0, 0, 0, 1]\n",
    "m = len(Xs)\n",
    "\n",
    "# Constantes auxiliares.\n",
    "minus = Const(-1)\n",
    "one = Const(1)\n",
    "\n",
    "# Estas são as verdadeiras variáveis do problema: os pesos e a constante!\n",
    "w0 = Var(\"w0\", init_value=0.0)\n",
    "w1 = Var(\"w1\", init_value=0.0)\n",
    "b = Var(\"b\", init_value=0.0)\n",
    "\n",
    "for epoch in range(max_iter):\n",
    "    #\n",
    "    # PASSO 1: Calcula a função de perda sobre todas as amostras.\n",
    "    #\n",
    "    \n",
    "    loss = Const(0)  # Todos os valores tem que ser convertidos para objetos.\n",
    "    # Para cada amostra de treinamento.\n",
    "    for xval, yval in zip(Xs, ys):\n",
    "        # Cria objetos para as features e o target.\n",
    "        x0 = Const(xval[0])\n",
    "        x1 = Const(xval[1])\n",
    "        y = Const(yval)\n",
    "\n",
    "        # Cria o objeto da predição.\n",
    "        y_pred = Logistic(Add(b, Add(Mul(x0, w0), Mul(x1, w1))))\n",
    "\n",
    "        # Cria a parcela da função de perda correspondente a esta amostra de\n",
    "        # treinamento.\n",
    "        loss = Add(\n",
    "            loss,\n",
    "            Mul(\n",
    "                minus,\n",
    "                Add(\n",
    "                    Mul(  # y * log(yhat)\n",
    "                        y,\n",
    "                        Log(y_pred),\n",
    "                    ),\n",
    "                    Mul(    # (1 - y) * log(1 - yhat)\n",
    "                        Add(one, Mul(minus, y)),\n",
    "                        Log(Add(one, Mul(minus, y_pred))),\n",
    "                    ),\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "    loss = Mul(Const(1/m), loss)  # Para tirar a média.\n",
    "    loss.evaluate()\n",
    "    \n",
    "    #\n",
    "    # PASSO 2: Calcula as derivadas da perda em relação às variáveis (i.e. \n",
    "    # os pesos e a constante).\n",
    "    #\n",
    "    loss.backpropagate(1.0)\n",
    "\n",
    "    # PASSO 3: Executa o passo de aprendizado do algoritmo.\n",
    "    w0.value -= alpha * w0.gradient\n",
    "    w1.value -= alpha * w1.gradient\n",
    "    b.value -= alpha * b.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(w0:7.414311377625753) (w1:7.414311377625753) (b:-11.294073552477853)\n"
     ]
    }
   ],
   "source": [
    "print(w0, w1, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 1.244631455107799e-05\n",
      "0 1 0 0.020237712189812407\n",
      "1 0 0 0.020237712189812407\n",
      "1 1 1 0.9716549737629768\n"
     ]
    }
   ],
   "source": [
    "for xval, yval in zip(Xs, ys):\n",
    "    x0 = Const(xval[0])\n",
    "    x1 = Const(xval[1])\n",
    "    y = Const(yval)\n",
    "    y_pred = Logistic(Add(b, Add(Mul(x0, w0), Mul(x1, w1))))\n",
    "    y_pred.evaluate()\n",
    "    print(x0, x1, y, y_pred.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow é uma biblioteca para computação distribuída, incluindo GPUs. A biblioteca TensorFlow permite o processamento de **tensores** (matrizes n-dimensionais: um valor solitário é um tensor de grau zero, uma lista de valores é um tensor de grau 1, uma matriz é um tensor de grau 2, etc) através de um *grafo de computação* sobre o qual os dados **fluem** (daí o nome TensorFlow).\n",
    "\n",
    "A idéia básica é a seguinte:\n",
    "\n",
    "- Os dados são tabelas n-dimensionais. O caso mais comum é matrizes.\n",
    "\n",
    "- A computação é definida como um grafo\n",
    "\n",
    "TensorFlow foi criado para trabalhar com dados em larga escala: podemos construir modelos com milhões de parâmetros e bilhões de pontos de dados! Aliás, é para isso que a biblioteca foi criada pelo time de machine learning do Google (o projeto Google Brain), e é usado em serviços de larga escala como o Google Search, Google Photos, etc.\n",
    "\n",
    "**Instalação**\n",
    "\n",
    "```bash\n",
    "pip install tensorflow\n",
    "```\n",
    "\n",
    "ou \n",
    "\n",
    "```bash\n",
    "pip install tensorflow-gpu\n",
    "```\n",
    "\n",
    "se você tem uma GPU NVidia compatível com a biblioteca CUDA. Neste caso você também precisa instalar os drivers CUDA. Siga as instruções completas de instalação do TensorFlow em https://www.tensorflow.org/install.\n",
    "\n",
    "Você pode também rodar os notebooks desta seção do curso no Google Colab: https://colab.research.google.com/\n",
    "\n",
    "**Documentação**\n",
    "\n",
    "https://www.tensorflow.org/programmers_guide/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos implementar a regressáo logística mais uma vez, mas agora com TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def linear_tf(w, b, X):\n",
    "    return X @ w + b\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def logistic_tf(x):\n",
    "    return 1.0 / (1.0 + tf.math.exp(-x))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def model(w, b, X):\n",
    "    return logistic_tf(linear_tf(w, b, X))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def cross_entropy_tf(y, y_pred):\n",
    "    m = y.shape[0]\n",
    "    cross = (1.0 / m) * tf.reduce_sum(\n",
    "        -y * tf.math.log(y_pred) - (1 - y) * tf.math.log(1 - y_pred)\n",
    "    )\n",
    "    return cross\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def loss_tf(X, y, w, b):\n",
    "    y_pred = model(w, b, X)\n",
    "    return cross_entropy_tf(y, y_pred)\n",
    "\n",
    "\n",
    "X = tf.constant(\n",
    "    [\n",
    "        [0.0, 0.0],\n",
    "        [0.0, 1.0],\n",
    "        [1.0, 0.0],\n",
    "        [1.0, 1.0],\n",
    "    ]\n",
    ")\n",
    "y = tf.constant(\n",
    "    [\n",
    "        [0.0],\n",
    "        [0.0],\n",
    "        [0.0],\n",
    "        [1.0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "w = tf.Variable([[0.0], [0.0]])\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "epochs = 1000\n",
    "alpha = 1.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # GradientTape é o mecanismo de contabilidade dos gradientes no TensorFlow.\n",
    "    with tf.GradientTape() as tape:\n",
    "        eps = loss_tf(X, y, w, b)\n",
    "    grad_w, grad_b = tape.gradient(eps, [w, b])\n",
    "    w.assign_sub(alpha * grad_w)\n",
    "    b.assign_sub(alpha * grad_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
       "array([[7.4143085],\n",
       "       [7.4143085]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-11.294069>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       "array([[1.2446368e-05],\n",
       "       [2.0237742e-02],\n",
       "       [2.0237742e-02],\n",
       "       [9.7165495e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(w, b, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você monitorar o uso da sua GPU verá que ela será posta em ação neste código:\n",
    "\n",
    "![](cuda.png)\n",
    "\n",
    "Observe que o TensorFlow alocou quase toda a memória da sua GPU (por precaução) e acionou os processadores numéricos da GPU. Este é um exemplo pequeno, e quase todo o trabalho da GPU foi criar os *kernels* de processamento, copiar dados da memória principal (*host memory*, a *RAM* da sua máquina) para a memória da GPU (*device memory*), e copiar de volta esses dados (*device-to-host* agora).\n",
    "\n",
    "Podemos trocar nosso *gradient descent* simples por um outro regime de *gradient descent* mais sofisticado como o Adam (Adaptive Moment Estimation) usando os otimizadores pré-implementados do TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def linear_tf(w, b, X):\n",
    "    return X @ w + b\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def logistic_tf(x):\n",
    "    return 1.0 / (1.0 + tf.math.exp(-x))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def model(w, b, X):\n",
    "    return logistic_tf(linear_tf(w, b, X))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def cross_entropy_tf(y, y_pred):\n",
    "    m = y.shape[0]\n",
    "    cross = (1.0 / m) * tf.reduce_sum(\n",
    "        -y * tf.math.log(y_pred) - (1 - y) * tf.math.log(1 - y_pred)\n",
    "    )\n",
    "    return cross\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def loss_tf(X, y, w, b):\n",
    "    y_pred = model(w, b, X)\n",
    "    return cross_entropy_tf(y, y_pred)\n",
    "\n",
    "\n",
    "X = tf.constant(\n",
    "    [\n",
    "        [0.0, 0.0],\n",
    "        [0.0, 1.0],\n",
    "        [1.0, 0.0],\n",
    "        [1.0, 1.0],\n",
    "    ]\n",
    ")\n",
    "y = tf.constant(\n",
    "    [\n",
    "        [0.0],\n",
    "        [0.0],\n",
    "        [0.0],\n",
    "        [1.0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "w = tf.Variable([[0.0], [0.0]])\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "epochs = 1000\n",
    "alpha = 1.0\n",
    "\n",
    "# Para usar um otimizador, precisamos criá-lo.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=alpha)\n",
    "\n",
    "for _ in range(epochs):\n",
    "    # O otimizador tem dois argumentos: uma função sem parâmetros (estranho!)\n",
    "    # e uma lista de variáveis que serão otimizadas.\n",
    "    optimizer.minimize(lambda: loss_tf(X, y, w, b), var_list=[w, b])\n",
    "\n",
    "# Após rodar vários epochs (passagens completas pelos dados) temos nas\n",
    "# próprias variáveis w e b os seus valores ótimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
       "array([[16.914984],\n",
       "       [16.914984]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-25.480349>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       "array([[8.5906334e-12],\n",
       "       [1.9055772e-04],\n",
       "       [1.9055772e-04],\n",
       "       [9.9976355e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(w, b, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uma rede neural multicamadas\n",
    "\n",
    "Uma camada de uma rede neural é simplesmente uma chamada da função `linear` seguida de uma chamada de uma *função de ativação* (a função logística é um exemplo de função de ativação). Uma rede neural multicamadas é uma sequência de camadas. Simples! \n",
    "\n",
    "As redes multicamadas são necessárias para resolver problemas mais complexos, que não podem ser resolvidos por uma regressão logística simples. Por exemplo, como uma regressão logística resolveria o seguinte problema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(\n",
    "    [\n",
    "        [0.0, 0.0],\n",
    "        [0.0, 1.0],\n",
    "        [1.0, 0.0],\n",
    "        [1.0, 1.0],\n",
    "    ]\n",
    ")\n",
    "y = tf.constant(\n",
    "    [\n",
    "        [0.0],\n",
    "        [1.0],\n",
    "        [1.0],\n",
    "        [0.0],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade**: Tente achar pesos e constante que resolvam o problema acima com regressão logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos implementar uma rede neural multicamadas, com funções de ativação diferentes. Uma das funções de ativação mais populares recentemente é a \"Rectified Linear Unit\" - ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def relu_tf(x):\n",
    "    return tf.math.maximum(x, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa função `linear` já trabalha com multiplas entradas e multiplas saidas: basta usar uma matriz `w` para os pesos que seja compatível com os tamanhos de entrada e saída. O mesmo vale para os pesos `b`. Vamos fazer uma camada de rede neural que tem duas entradas e duas saídas, com função de ativação relu, seguida de uma camada de duas entradas e uma saída, com função de ativação sigmoide. Vamos otimizar essa rede usando um otimizador Adam. A função de perda será, como de costume, a entropia cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.6665262, shape=(), dtype=float32)\n",
      "tf.Tensor(0.008741024, shape=(), dtype=float32)\n",
      "tf.Tensor(0.002896754, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0015090134, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0009494979, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00065689895, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0004852253, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000374028, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00029841304, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00024365107, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def linear_tf(w, b, X):\n",
    "    return X @ w + b\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def logistic_tf(x):\n",
    "    return 1.0 / (1.0 + tf.math.exp(-x))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def model(w0, b0, w1, b1, X):\n",
    "    layer1 = relu_tf(linear_tf(w0, b0, X))\n",
    "    layer2 = logistic_tf(linear_tf(w1, b1, layer1))\n",
    "    return layer2\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def cross_entropy_tf(y, y_pred):\n",
    "    m = y.shape[0]\n",
    "    cross = (1.0 / m) * tf.reduce_sum(\n",
    "        -y * tf.math.log(y_pred) - (1 - y) * tf.math.log(1 - y_pred)\n",
    "    )\n",
    "    return cross\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def loss_tf(X, y, w0, b0, w1, b1):\n",
    "    y_pred = model(w0, b0, w1, b1, X)\n",
    "    return cross_entropy_tf(y, y_pred)\n",
    "\n",
    "\n",
    "w0 = tf.Variable(\n",
    "    [\n",
    "        [1.0, 1.0],\n",
    "        [-1.0, -1.0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "b0 = tf.Variable(\n",
    "    [\n",
    "        [0.5, 0.5],\n",
    "    ]\n",
    ")\n",
    "\n",
    "w1 = tf.Variable(\n",
    "    [\n",
    "        [1.0],\n",
    "        [-1.0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "b1 = tf.Variable(0.5)\n",
    "\n",
    "epochs = 1000\n",
    "alpha = 0.1\n",
    "\n",
    "# Para usar um otimizador, precisamos criá-lo.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=alpha)\n",
    "opt_loss = lambda: loss_tf(X, y, w0, b0, w1, b1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # O otimizador tem dois argumentos: uma função sem parâmetros (estranho!)\n",
    "    # e uma lista de variáveis que serão otimizadas.\n",
    "    optimizer.minimize(opt_loss, var_list=[w0, b0, w1, b1])\n",
    "    if epoch % 100 == 0:\n",
    "        print(opt_loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       "array([[1.1681593e-04],\n",
       "       [9.9943012e-01],\n",
       "       [9.9994302e-01],\n",
       "       [6.7745830e-05]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(w0, b0, w1, b1, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[ 5.02569  ,  3.1929967],\n",
       "       [-5.02579  , -3.0912116]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.0799025e-04, 3.0909736e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
       "array([[ 7.143029],\n",
       "       [-5.346258]], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=7.4695783>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claro, eu inicializei os pesos na mão, para fazer convergir! Vamos ver nas outras aulas como criar redes neurais \"de verdade\" usando Keras, e vamos discutir aspectos como inicialização, convergência, regularização, etc. Até a próxima!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
